{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import urllib.parse\n",
    "import codecs\n",
    "from pyquery import PyQuery as pq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log into Danbooru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_requests = requests.session()\n",
    "auth_token = None\n",
    "    \n",
    "login_url = 'https://danbooru.donmai.us/session/new'\n",
    "headers = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36'}\n",
    "result = session_requests.get(login_url, headers = headers)\n",
    "\n",
    "login_page = pq(result.text)\n",
    "authenticity_token = urllib.parse.quote(login_page('input').attr('value'),safe='')\n",
    "#print(authenticity_token)\n",
    "\n",
    "login_data = {\n",
    "    'authenticity_token': authenticity_token,\n",
    "    'url': '',\n",
    "    'name': 'komeiji_nori',\n",
    "    'password': ,\n",
    "    'remember': '1',   \n",
    "    'commit': 'Submit'\n",
    "}\n",
    "\n",
    "resp = session_requests.post(url = 'https://danbooru.donmai.us/session', data = login_data, headers = headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Wiki Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wiki_url = 'https://danbooru.donmai.us/wiki_pages/62620'\n",
    "# wiki_page_data = session_requests.get(wiki_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to parse character list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def chara_map_creation(wiki_page_data):\n",
    "#     chara_map = {}\n",
    "#     wiki_page_query = pq(wiki_page_data.text)\n",
    "#     for tag_li in wiki_page_query('li'):\n",
    "#         li_query = pq(tag_li)\n",
    "#         li_a_class = li_query('a').attr('class') or ''\n",
    "#         if 'dtext-link' in li_a_class:\n",
    "#             li_text = li_query.text()\n",
    "#             try:\n",
    "#                 chara_name = re.search('(?!.* /)(?<=/ ).*',li_text).group(0)\n",
    "#             except:\n",
    "#                 try:\n",
    "#                     chara_name = li_query('a').text()\n",
    "#                 except:\n",
    "#                     chara_name = ''\n",
    "#             chara_url = li_query('a').attr('href') or ''\n",
    "#             if chara_url:\n",
    "#                 chara_tag = re.search('(?<=title=).*',chara_url).group(0)\n",
    "#             if chara_name:\n",
    "#                 chara_map[chara_name] = chara_tag\n",
    "#     return chara_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output Chara Dictionary. Cleaned and edited outside of python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kantai_chara = chara_map_creation(wiki_page_data)\n",
    "# dict_file = codecs.open('kantai_chara_dict.txt', 'w', 'utf-8')\n",
    "\n",
    "# for i in kantai_chara:\n",
    "#     dict_file.write('{}\\t{}\\n'.format(i,kantai_chara[i]))\n",
    "\n",
    "# dict_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n"
     ]
    }
   ],
   "source": [
    "new_url = 'https://danbooru.donmai.us/counts/posts?tags=shimakaze_(kantai_collection)+rating:safe+parent:None+amatsukaze_(kantai_collection)'\n",
    "page_data = session_requests.get(new_url)\n",
    "page_query = pq(page_data.text)\n",
    "for tag_div in page_query('div'):\n",
    "    div_query = pq(tag_div)\n",
    "    div_id = div_query.attr('id')\n",
    "    if div_id == 'a-posts':\n",
    "        count = div_query.text()\n",
    "        count = re.findall(r'\\d+', count)[0]\n",
    "        print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
