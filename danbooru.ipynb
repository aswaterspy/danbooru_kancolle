{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import urllib.parse\n",
    "import codecs\n",
    "import time\n",
    "from random import randint\n",
    "from pyquery import PyQuery as pq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log into Danbooru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_requests = requests.session()\n",
    "auth_token = None\n",
    "    \n",
    "login_url = 'https://danbooru.donmai.us/session/new'\n",
    "headers = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36'}\n",
    "result = session_requests.get(login_url, headers = headers)\n",
    "\n",
    "login_page = pq(result.text)\n",
    "authenticity_token = urllib.parse.quote(login_page('input').attr('value'),safe='')\n",
    "#print(authenticity_token)\n",
    "\n",
    "login_data = {\n",
    "    'authenticity_token': authenticity_token,\n",
    "    'url': '',\n",
    "    'name': 'komeiji_nori',\n",
    "    'password': ,\n",
    "    'remember': '1',   \n",
    "    'commit': 'Submit'\n",
    "}\n",
    "\n",
    "resp = session_requests.post(url = 'https://danbooru.donmai.us/session', data = login_data, headers = headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Wiki Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wiki_url = 'https://danbooru.donmai.us/wiki_pages/62620'\n",
    "# wiki_page_data = session_requests.get(wiki_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to parse character list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def chara_map_creation(wiki_page_data):\n",
    "#     chara_map = {}\n",
    "#     wiki_page_query = pq(wiki_page_data.text)\n",
    "#     for tag_li in wiki_page_query('li'):\n",
    "#         li_query = pq(tag_li)\n",
    "#         li_a_class = li_query('a').attr('class') or ''\n",
    "#         if 'dtext-link' in li_a_class:\n",
    "#             li_text = li_query.text()\n",
    "#             try:\n",
    "#                 chara_name = re.search('(?!.* /)(?<=/ ).*',li_text).group(0)\n",
    "#             except:\n",
    "#                 try:\n",
    "#                     chara_name = li_query('a').text()\n",
    "#                 except:\n",
    "#                     chara_name = ''\n",
    "#             chara_url = li_query('a').attr('href') or ''\n",
    "#             if chara_url:\n",
    "#                 chara_tag = re.search('(?<=title=).*',chara_url).group(0)\n",
    "#             if chara_name:\n",
    "#                 chara_map[chara_name] = chara_tag\n",
    "#     return chara_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output Chara Dictionary. Cleaned and edited outside of python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kantai_chara = chara_map_creation(wiki_page_data)\n",
    "# dict_file = codecs.open('kantai_chara_dict.txt', 'w', 'utf-8')\n",
    "\n",
    "# for i in kantai_chara:\n",
    "#     dict_file.write('{}\\t{}\\n'.format(i,kantai_chara[i]))\n",
    "\n",
    "# dict_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n"
     ]
    }
   ],
   "source": [
    "# Test Block\n",
    "# new_url = 'https://danbooru.donmai.us/counts/posts?tags=shimakaze_(kantai_collection)+rating:safe+parent:None+amatsukaze_(kantai_collection)'\n",
    "# page_data = session_requests.get(new_url)\n",
    "# page_query = pq(page_data.text)\n",
    "# for tag_div in page_query('div'):\n",
    "#     div_query = pq(tag_div)\n",
    "#     div_id = div_query.attr('id')\n",
    "#     if div_id == 'a-posts':\n",
    "#         count = div_query.text()\n",
    "#         count = re.findall(r'\\d+', count)[0]\n",
    "#         print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "murakumo_%28kantai_collection%29\n",
      "shimakaze_%28kantai_collection%29\n"
     ]
    }
   ],
   "source": [
    "dict_file = codecs.open('kantai_chara_dict_final.txt', 'r', 'utf-8')\n",
    "chara_dict = {}\n",
    "\n",
    "for line in dict_file:\n",
    "    name_pair = (line[:-1]).split('\\t')\n",
    "    chara_dict[name_pair[0]] = name_pair[1]\n",
    "\n",
    "print(chara_dict['叢雲'])\n",
    "print(chara_dict['島風'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_danbooru(key):\n",
    "    \n",
    "    output_dict = {}\n",
    "    parent_flag = ['all','parent%3Anone']\n",
    "    rating_flag = ['all','rating%3Aexplicit','rating%3Aquestionable','rating%3Asafe']\n",
    "    \n",
    "    for i in parent_flag:\n",
    "        for j in rating_flag:\n",
    "            \n",
    "            #build query url\n",
    "            chara_url = 'https://danbooru.donmai.us/counts/posts?tags=+-official_art'\n",
    "            if i != 'all':\n",
    "                chara_url = chara_url + '+' + i\n",
    "            if j != 'all':\n",
    "                chara_url = chara_url + '+' + j\n",
    "            if key != '島風':\n",
    "                chara_url = chara_url + '+' + chara_dict[key]\n",
    "            else:\n",
    "                chara_url = chara_url + '+' + chara_dict[key] + '+-shimakaze_%28kantai_collection%29_%28cosplay%29'\n",
    "\n",
    "            #get query url and count\n",
    "            chara_count_page = session_requests.get(chara_url)\n",
    "            chara_count_query = pq(chara_count_page.text)\n",
    "\n",
    "            for tag_div in chara_count_query('div'):\n",
    "                div_query = pq(tag_div)\n",
    "                div_id = div_query.attr('id')\n",
    "                if div_id == 'a-posts':\n",
    "                    count = div_query.remove('a').text()\n",
    "                    count = re.findall(r'\\d+', count)[0]\n",
    "\n",
    "            output_dict_key = (key, urllib.parse.unquote(i), urllib.parse.unquote(j))\n",
    "            output_dict[output_dict_key] = count\n",
    "    \n",
    "            # Waits before sending next request\n",
    "            time.sleep(10 + randint(0,10))\n",
    "            \n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = {}\n",
    "\n",
    "for i in chara_dict:\n",
    "    a = count_danbooru(i)\n",
    "    final_result = {**final_result, **a}\n",
    "\n",
    "final_output_file = codecs.open('final.txt', 'w', 'utf-8')\n",
    "\n",
    "for i in final_result:\n",
    "    chara_name, parent_flag, ratings_flag = i\n",
    "    final_output_file.write('{}\\t{}\\t{}\\t{}\\n'.format(chara_name, parent_flag, ratings_flag, final_result[i]))\n",
    "\n",
    "final_output_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
